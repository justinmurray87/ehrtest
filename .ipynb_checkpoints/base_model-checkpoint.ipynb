{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model with TF DenseFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dependancies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this should move to a create lifecycle config\n",
    "# import libraries\n",
    "# import boto3,sagemaker\n",
    "import   re, sys, math, json, os, urllib.request\n",
    "# from sagemaker import get_execution_role\n",
    "import numpy as np                                \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt                   \n",
    "from IPython.display import Image                 \n",
    "from IPython.display import display               \n",
    "from time import gmtime, strftime                 \n",
    "# from sagemaker.predictor import csv_serializer   \n",
    "\n",
    "#this should move to a create lifecycle config\n",
    "# Define IAM role\n",
    "# role = get_execution_role()\n",
    "# prefix = 'sagemaker/ehrsample2'\n",
    "# containers = {'us-west-2': '433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:latest',\n",
    "#               'us-east-1': '811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest',\n",
    "#               'us-east-2': '825641698319.dkr.ecr.us-east-2.amazonaws.com/xgboost:latest',\n",
    "#               'eu-west-1': '685385470294.dkr.ecr.eu-west-1.amazonaws.com/xgboost:latest'} # each region has its XGBoost container\n",
    "# my_region = boto3.session.Session().region_name # set the region of the instance\n",
    "# print(\"Success - the MySageMakerInstance is in the \" + my_region + \" region. You will use the \" + containers[my_region] + \" container for your SageMaker endpoint.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S3 error:  An error occurred (BucketAlreadyOwnedByYou) when calling the CreateBucket operation: Your previous request to create the named bucket succeeded and you already own it.\n"
     ]
    }
   ],
   "source": [
    "#this should move to a create lifecycle config\n",
    "#create S3 Bucket\n",
    "bucket_name = 'ehrsample2' # <--- CHANGE THIS VARIABLE TO A UNIQUE NAME FOR YOUR BUCKET\n",
    "s3 = boto3.resource('s3')\n",
    "try:\n",
    "    if  my_region == 'us-east-1':\n",
    "      s3.create_bucket(Bucket=bucket_name)\n",
    "    else: \n",
    "      s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration={ 'LocationConstraint': my_region })\n",
    "    print('S3 bucket created successfully')\n",
    "except Exception as e:\n",
    "    print('S3 error: ',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach',\n",
    "       'exang', 'oldpeak', 'slope', 'ca', 'thal', 'num_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Data loaded into dataframe.\n",
      "Success: Data loaded into dataframe.\n"
     ]
    }
   ],
   "source": [
    "#this should move to a start lifecycle config (or should this be a processing job?)\n",
    "\n",
    "#swiss data set\n",
    "swiss_dataset_path = \"./processedswitzerland.txt\"\n",
    "\n",
    "#old code\n",
    "#try:\n",
    "#  urllib.request.urlretrieve (\"s3://ehrsample2/processedswitzerland.csv\", \"processedswitzerland.csv.csv\")\n",
    "#  print('Success: downloaded swiss_setn.csv.')\n",
    "#except Exception as e:\n",
    "#  print('Data load error: ',e)\n",
    "\n",
    "try:\n",
    "  swiss_df = pd.read_csv(swiss_dataset_path,  names=column_list).replace('?', np.nan)\n",
    "  print('Success: Data loaded into dataframe.')\n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)\n",
    "\n",
    "#cleveland data set\n",
    "cleveland_dataset_path = \"./processedcleveland.txt\"\n",
    "\n",
    "#old code\n",
    "#try:\n",
    "#  urllib.request.urlretrieve (\"s3://ehrsample2/processedcleveland.csv\", \"processedcleveland.csv\")\n",
    "#  print('Success: downloaded cleveland_setn.csv.')\n",
    "#except Exception as e:\n",
    "#  print('Data load error: ',e)\n",
    "\n",
    "try:\n",
    "  cleveland_df = pd.read_csv(cleveland_dataset_path,  names=column_list).replace('?', np.nan)\n",
    "  print('Success: Data loaded into dataframe.')\n",
    "except Exception as e:\n",
    "    print('Data load error: ',e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   age  sex  cp trestbps  chol  fbs restecg thalach exang oldpeak slope   ca  \\\n",
      "0   32    1   1       95     0  NaN       0     127     0      .7     1  NaN   \n",
      "1   34    1   4      115     0  NaN     NaN     154     0      .2     1  NaN   \n",
      "2   35    1   4      NaN     0  NaN       0     130     1     NaN   NaN  NaN   \n",
      "3   36    1   4      110     0  NaN       0     125     1       1     2  NaN   \n",
      "\n",
      "  thal  num_label  \n",
      "0  NaN          1  \n",
      "1  NaN          1  \n",
      "2    7          3  \n",
      "3    6          1  \n"
     ]
    }
   ],
   "source": [
    "swissdfsample = swiss_df.head(4)\n",
    "print(swissdfsample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old code from pre-S3, can remove\n",
    "#from https://archive.ics.uci.edu/ml/datasets/Heart+Disease\n",
    "#swiss_dataset_path = \"./data/heart_disease_data/processed_swiss.csv\"\n",
    "#swiss_df = pd.read_csv(swiss_dataset_path).replace('?', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#old code from pre-S3, can remove\n",
    "#cleveland_df = pd.read_csv(\"./data/heart_disease_data/processed.cleveland.txt\",  names=column_list).replace('?', np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#combine both sources into one\n",
    "combined_heart_df = pd.concat([swiss_df, cleveland_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "426"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_heart_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    age  sex   cp trestbps  chol  fbs restecg thalach exang oldpeak slope  \\\n",
      "0  32.0  1.0  1.0       95   0.0  NaN       0     127     0      .7     1   \n",
      "1  34.0  1.0  4.0      115   0.0  NaN     NaN     154     0      .2     1   \n",
      "2  35.0  1.0  4.0      NaN   0.0  NaN       0     130     1     NaN   NaN   \n",
      "3  36.0  1.0  4.0      110   0.0  NaN       0     125     1       1     2   \n",
      "\n",
      "    ca thal  num_label  \n",
      "0  NaN  NaN          1  \n",
      "1  NaN  NaN          1  \n",
      "2  NaN    7          3  \n",
      "3  NaN    6          1  \n"
     ]
    }
   ],
   "source": [
    "dfsample = combined_heart_df.head(4)\n",
    "print(dfsample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Preparation\n",
    "- This simple verson of the dataset has only a three features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['sex',  'age', 'trestbps', 'thalach' ]\n",
    "bp_df = combined_heart_df[selected_features].replace({1:\"male\", 0:\"female\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST how many rows with at least a single null value\n",
    "sum(bp_df.apply(lambda x: sum(x.isnull().values), axis = 1)>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bp_df[bp_df['trestbps'].isnull()==True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>thalach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>95</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>115</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>110</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>105</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex   age trestbps thalach\n",
       "0    male  32.0       95     127\n",
       "1    male  34.0      115     154\n",
       "2    male  35.0      NaN     130\n",
       "3    male  36.0      110     125\n",
       "4  female  38.0      105     166"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bp_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for simplicity will drop rows with null since predictor is null \n",
    "clean_df = bp_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>thalach</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>95</td>\n",
       "      <td>127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>115</td>\n",
       "      <td>154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>male</td>\n",
       "      <td>36.0</td>\n",
       "      <td>110</td>\n",
       "      <td>125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>105</td>\n",
       "      <td>166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>110</td>\n",
       "      <td>156</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      sex   age trestbps thalach\n",
       "0    male  32.0       95     127\n",
       "1    male  34.0      115     154\n",
       "3    male  36.0      110     125\n",
       "4  female  38.0      105     166\n",
       "5  female  38.0      110     156"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df['trestbps'].loc[:] = clean_df['trestbps'].loc[:].astype(float)\n",
    "clean_df['thalach'].loc[:] = clean_df['thalach'].loc[:].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#adapted from https://www.tensorflow.org/tutorials/structured_data/feature_columns\n",
    "def df_to_dataset(df, predictor,  batch_size=32):\n",
    "    df = df.copy()\n",
    "    labels = df.pop(predictor)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(df), labels))\n",
    "    ds = ds.shuffle(buffer_size=len(df))\n",
    "    ds = ds.batch(batch_size)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split 80 20 train test split - not ideal \n",
    "train_dataset = clean_df.sample(frac=0.8,random_state=0)\n",
    "test_dataset = clean_df.drop(train_dataset.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "PREDICTOR_FIELD = 'trestbps'\n",
    "batch_size = 128\n",
    "train_ds = df_to_dataset(train_dataset, PREDICTOR_FIELD, batch_size=batch_size)\n",
    "test_ds = df_to_dataset(test_dataset, PREDICTOR_FIELD, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ({sex: (None,), age: (None,), thalach: (None,)}, (None,)), types: ({sex: tf.string, age: tf.float64, thalach: tf.float64}, tf.float64)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create TF numeric feature\n",
    "tf_numeric_age_feature = tf.feature_column.numeric_column(key='age', default_value=0, dtype=tf.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_list = [ 0, 18, 25, 40, 55, 65, 80, 100]\n",
    "#create TF bucket feature from numeric feature\n",
    "tf_numeric_age_feature\n",
    "tf_bucket_age_feature = tf.feature_column.bucketized_column(source_column=tf_numeric_age_feature, boundaries= b_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using list b/c small number of unique values\n",
    "gender_vocab = tf.feature_column.categorical_column_with_vocabulary_list(\n",
    "      'sex', bp_df['sex'].unique())\n",
    "gender_one_hot = tf.feature_column.indicator_column(gender_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add cross features - use example from TF\n",
    "crossed_age_gender_feature = tf.feature_column.crossed_column([tf_bucket_age_feature, gender_vocab], hash_bucket_size=1000)\n",
    "tf_crossed_age_gender_feature = tf.feature_column.indicator_column(crossed_age_gender_feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = [ tf_crossed_age_gender_feature, tf_bucket_age_feature, gender_one_hot ]\n",
    "dense_feature_layer = tf.keras.layers.DenseFeatures(feature_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use same architecture as example\n",
    "def build_model(dense_feature_layer):\n",
    "  model = tf.keras.Sequential([\n",
    "    dense_feature_layer,\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(1)\n",
    "  ])\n",
    "\n",
    "  optimizer = tf.keras.optimizers.RMSprop(0.001)\n",
    "\n",
    "  model.compile(loss='mse',\n",
    "                optimizer=optimizer,\n",
    "                metrics=['mae', 'mse'])\n",
    "  return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model(dense_feature_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'sex': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>, 'age': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'thalach': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'sex': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>, 'age': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'thalach': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "3/3 [==============================] - 3s 9ms/step - loss: 17526.0947 - mae: 130.9446 - mse: 17526.0947\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 17294.6479 - mae: 130.1895 - mse: 17294.6479\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 17482.0942 - mae: 130.8576 - mse: 17482.0942\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 17204.7329 - mae: 129.8514 - mse: 17204.7329\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 17259.9165 - mae: 129.9986 - mse: 17259.9165\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 17257.9785 - mae: 129.9403 - mse: 17257.9785\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 17392.3848 - mae: 130.4854 - mse: 17392.3848\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 17014.3423 - mae: 129.0403 - mse: 17014.3423\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 16852.8623 - mae: 128.5150 - mse: 16852.8623\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 16794.1499 - mae: 128.2110 - mse: 16794.1499\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 16594.1016 - mae: 127.4485 - mse: 16594.1016\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 16553.5073 - mae: 127.1838 - mse: 16553.5073\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 16292.1655 - mae: 126.2367 - mse: 16292.1655\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 16433.5466 - mae: 126.7403 - mse: 16433.5466\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 16003.9998 - mae: 125.0573 - mse: 16003.9998\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 15861.0977 - mae: 124.4846 - mse: 15861.0977\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 15844.2271 - mae: 124.3118 - mse: 15844.2271\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 15610.8376 - mae: 123.4194 - mse: 15610.8376\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 15481.5808 - mae: 122.8703 - mse: 15481.5808\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 14894.9182 - mae: 120.5765 - mse: 14894.9182\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 14736.6221 - mae: 119.9050 - mse: 14736.6221\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 14511.8096 - mae: 118.9388 - mse: 14511.8096\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 14308.4351 - mae: 118.0131 - mse: 14308.4351\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 13866.8542 - mae: 116.2486 - mse: 13866.8542\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 13684.4246 - mae: 115.4247 - mse: 13684.4246\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 13231.9509 - mae: 113.4043 - mse: 13231.9509\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 12850.5989 - mae: 111.7789 - mse: 12850.5989\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 12600.7495 - mae: 110.6560 - mse: 12600.7495\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 12277.5015 - mae: 109.1343 - mse: 12277.5015\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 12052.7498 - mae: 108.0575 - mse: 12052.7498\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 11464.5159 - mae: 105.3186 - mse: 11464.5159\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 11339.5608 - mae: 104.7370 - mse: 11339.5608\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 10757.8267 - mae: 101.9742 - mse: 10757.8267\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 10510.7646 - mae: 100.7760 - mse: 10510.7646\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 10145.6572 - mae: 98.8385 - mse: 10145.6572\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 9631.1726 - mae: 96.2366 - mse: 9631.1726\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 9307.3225 - mae: 94.5959 - mse: 9307.3225\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 9036.5493 - mae: 93.0445 - mse: 9036.5493\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 8714.7495 - mae: 91.2704 - mse: 8714.7495\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 8109.1589 - mae: 88.0257 - mse: 8109.1589\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 7711.2445 - mae: 85.7151 - mse: 7711.2445\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 7334.2701 - mae: 83.5307 - mse: 7334.2701\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 6886.6329 - mae: 80.8285 - mse: 6886.6329\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 6491.8481 - mae: 78.3272 - mse: 6491.8481\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 6118.3407 - mae: 75.8562 - mse: 6118.3407\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 5689.5790 - mae: 73.0072 - mse: 5689.5790\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 5364.8190 - mae: 70.8545 - mse: 5364.8190\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 5019.7770 - mae: 68.2959 - mse: 5019.7770\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 4607.4237 - mae: 65.1099 - mse: 4607.4237\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 4275.1472 - mae: 62.4416 - mse: 4275.1472\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 3905.5728 - mae: 59.3140 - mse: 3905.5728\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 3479.6086 - mae: 56.0691 - mse: 3479.6086\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 3286.2899 - mae: 54.1356 - mse: 3286.2899\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2927.3447 - mae: 50.7055 - mse: 2927.3447\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 2638.7578 - mae: 47.7482 - mse: 2638.7578\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 2348.8786 - mae: 44.5356 - mse: 2348.8786\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 2165.8545 - mae: 42.3335 - mse: 2165.8545\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1850.8597 - mae: 38.6759 - mse: 1850.8597\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 1627.6774 - mae: 35.8401 - mse: 1627.6774\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 1443.3452 - mae: 32.9060 - mse: 1443.3452\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1234.2648 - mae: 29.9156 - mse: 1234.2648\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 1029.9692 - mae: 26.8520 - mse: 1029.9692\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 891.9515 - mae: 24.3505 - mse: 891.9515\n",
      "Epoch 64/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 7ms/step - loss: 768.3348 - mae: 21.8972 - mse: 768.3348\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 699.4178 - mae: 20.2496 - mse: 699.4178\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 562.0435 - mae: 18.1602 - mse: 562.0435\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 521.9364 - mae: 17.2157 - mse: 521.9364\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 411.2986 - mae: 15.2486 - mse: 411.2986\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 403.0113 - mae: 15.1844 - mse: 403.0113\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 378.6907 - mae: 14.9459 - mse: 378.6907\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 366.5300 - mae: 14.8107 - mse: 366.5300\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 357.0646 - mae: 14.4295 - mse: 357.0646\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 332.8132 - mae: 14.1492 - mse: 332.8132\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 350.3179 - mae: 14.5342 - mse: 350.3179\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 335.5482 - mae: 14.4213 - mse: 335.5482\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 350.1117 - mae: 14.5795 - mse: 350.1117\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 337.3114 - mae: 14.3994 - mse: 337.3114\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 343.8770 - mae: 14.5936 - mse: 343.8770\n",
      "Epoch 79/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 342.5364 - mae: 14.4189 - mse: 342.5364\n",
      "Epoch 80/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 335.0931 - mae: 14.3594 - mse: 335.0931\n",
      "Epoch 81/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 321.1265 - mae: 14.1969 - mse: 321.1265\n",
      "Epoch 82/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 338.5583 - mae: 14.3532 - mse: 338.5583\n",
      "Epoch 83/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 333.5221 - mae: 14.2095 - mse: 333.5221\n",
      "Epoch 84/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 339.2371 - mae: 14.4230 - mse: 339.2371\n",
      "Epoch 85/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 340.2546 - mae: 14.4239 - mse: 340.2546\n",
      "Epoch 86/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 321.0808 - mae: 13.9791 - mse: 321.0808\n",
      "Epoch 87/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 323.3804 - mae: 14.0390 - mse: 323.3804\n",
      "Epoch 88/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 353.6212 - mae: 14.5346 - mse: 353.6212\n",
      "Epoch 89/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 316.8576 - mae: 13.8226 - mse: 316.8576\n",
      "Epoch 90/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 348.6935 - mae: 14.5005 - mse: 348.6935\n",
      "Epoch 91/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 316.0105 - mae: 13.9622 - mse: 316.0105\n",
      "Epoch 92/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 332.3994 - mae: 14.3714 - mse: 332.3994\n",
      "Epoch 93/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 337.8614 - mae: 14.3732 - mse: 337.8614\n",
      "Epoch 94/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 327.1371 - mae: 14.1889 - mse: 327.1371\n",
      "Epoch 95/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 351.7498 - mae: 14.7050 - mse: 351.7498\n",
      "Epoch 96/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 325.2724 - mae: 14.0571 - mse: 325.2724\n",
      "Epoch 97/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 333.6519 - mae: 14.2527 - mse: 333.6519\n",
      "Epoch 98/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 327.6514 - mae: 14.3451 - mse: 327.6514\n",
      "Epoch 99/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 334.7399 - mae: 14.3096 - mse: 334.7399\n",
      "Epoch 100/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 338.0312 - mae: 14.4265 - mse: 338.0312\n",
      "Epoch 101/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 330.8117 - mae: 14.2882 - mse: 330.8117\n",
      "Epoch 102/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 334.1588 - mae: 14.1504 - mse: 334.1587\n",
      "Epoch 103/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 321.3202 - mae: 13.9128 - mse: 321.3202\n",
      "Epoch 104/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 336.6085 - mae: 14.3198 - mse: 336.6085\n",
      "Epoch 105/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 335.2177 - mae: 14.3325 - mse: 335.2177\n",
      "Epoch 106/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 328.4029 - mae: 14.4115 - mse: 328.4029\n",
      "Epoch 107/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 352.1242 - mae: 14.6918 - mse: 352.1242\n",
      "Epoch 108/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 335.0111 - mae: 14.3288 - mse: 335.0111\n",
      "Epoch 109/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 335.2966 - mae: 14.2674 - mse: 335.2966\n",
      "Epoch 110/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 333.3944 - mae: 14.3279 - mse: 333.3944\n",
      "Epoch 111/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 324.5416 - mae: 14.1305 - mse: 324.5416\n",
      "Epoch 112/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 335.9627 - mae: 14.2783 - mse: 335.9627\n",
      "Epoch 113/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 322.9598 - mae: 14.0471 - mse: 322.9598\n",
      "Epoch 114/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 319.5926 - mae: 13.9588 - mse: 319.5926\n",
      "Epoch 115/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 346.7296 - mae: 14.6592 - mse: 346.7296\n",
      "Epoch 116/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 326.8406 - mae: 14.1743 - mse: 326.8406\n",
      "Epoch 117/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 328.8075 - mae: 14.2287 - mse: 328.8075\n",
      "Epoch 118/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 334.0577 - mae: 14.2472 - mse: 334.0577\n",
      "Epoch 119/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 332.8083 - mae: 14.2618 - mse: 332.8083\n",
      "Epoch 120/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 333.9133 - mae: 14.3844 - mse: 333.9133\n",
      "Epoch 121/1000\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 305.7378 - mae: 13.6433 - mse: 305.7378\n",
      "Epoch 122/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 321.6934 - mae: 13.9505 - mse: 321.6934\n",
      "Epoch 123/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 323.7784 - mae: 14.0462 - mse: 323.7784\n",
      "Epoch 124/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 334.0442 - mae: 14.3458 - mse: 334.0442\n",
      "Epoch 125/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 329.7790 - mae: 14.3319 - mse: 329.7789\n",
      "Epoch 126/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 330.5775 - mae: 14.2015 - mse: 330.5775\n",
      "Epoch 127/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 322.0564 - mae: 14.1042 - mse: 322.0564\n",
      "Epoch 128/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 348.6635 - mae: 14.4507 - mse: 348.6635\n",
      "Epoch 129/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 326.8500 - mae: 13.9931 - mse: 326.8500\n",
      "Epoch 130/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 328.1822 - mae: 14.2046 - mse: 328.1822\n",
      "Epoch 131/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 325.7590 - mae: 14.1193 - mse: 325.7590\n",
      "Epoch 132/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 324.4357 - mae: 14.2399 - mse: 324.4357\n",
      "Epoch 133/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 343.7646 - mae: 14.4445 - mse: 343.7646\n",
      "Epoch 134/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 325.8034 - mae: 14.1544 - mse: 325.8034\n",
      "Epoch 135/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 349.0584 - mae: 14.5438 - mse: 349.0584\n",
      "Epoch 136/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 8ms/step - loss: 330.9037 - mae: 14.1058 - mse: 330.9037\n",
      "Epoch 137/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 336.4469 - mae: 14.3876 - mse: 336.4469\n",
      "Epoch 138/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 319.5952 - mae: 14.1257 - mse: 319.5952\n",
      "Epoch 139/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 336.9305 - mae: 14.3950 - mse: 336.9305\n",
      "Epoch 140/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 330.4021 - mae: 14.2140 - mse: 330.4021\n",
      "Epoch 141/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 313.0311 - mae: 13.8393 - mse: 313.0311\n",
      "Epoch 142/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 313.9540 - mae: 13.8779 - mse: 313.9540\n",
      "Epoch 143/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 328.5103 - mae: 13.9937 - mse: 328.5103\n",
      "Epoch 144/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 340.4018 - mae: 14.4946 - mse: 340.4018\n",
      "Epoch 145/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 348.0871 - mae: 14.5097 - mse: 348.0871\n",
      "Epoch 146/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 338.1905 - mae: 14.3602 - mse: 338.1905\n",
      "Epoch 147/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 308.2995 - mae: 13.8319 - mse: 308.2995\n",
      "Epoch 148/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 314.1513 - mae: 13.8296 - mse: 314.1513\n",
      "Epoch 149/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 354.1957 - mae: 14.6902 - mse: 354.1957\n",
      "Epoch 150/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 356.4715 - mae: 14.8097 - mse: 356.4715\n",
      "Epoch 151/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 321.6800 - mae: 13.9581 - mse: 321.6800\n",
      "Epoch 152/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 338.7629 - mae: 14.3441 - mse: 338.7629\n",
      "Epoch 153/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 330.6870 - mae: 14.2797 - mse: 330.6870\n",
      "Epoch 154/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 313.4918 - mae: 13.9354 - mse: 313.4918\n",
      "Epoch 155/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 321.7383 - mae: 14.1608 - mse: 321.7383\n",
      "Epoch 156/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 328.0879 - mae: 13.8941 - mse: 328.0879\n",
      "Epoch 157/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 327.4925 - mae: 14.1942 - mse: 327.4925\n",
      "Epoch 158/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 336.1879 - mae: 14.3107 - mse: 336.1879\n",
      "Epoch 159/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 318.8881 - mae: 13.9895 - mse: 318.8881\n",
      "Epoch 160/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 327.6026 - mae: 14.3814 - mse: 327.6026\n",
      "Epoch 161/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 340.0564 - mae: 14.3333 - mse: 340.0564\n",
      "Epoch 162/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 316.6705 - mae: 13.7276 - mse: 316.6705\n",
      "Epoch 163/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 326.6425 - mae: 14.2138 - mse: 326.6425\n",
      "Epoch 164/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 350.4865 - mae: 14.6997 - mse: 350.4865\n",
      "Epoch 165/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 321.3167 - mae: 14.0942 - mse: 321.3167\n",
      "Epoch 166/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 333.9605 - mae: 14.5290 - mse: 333.9605\n",
      "Epoch 167/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 330.9593 - mae: 14.2991 - mse: 330.9593\n",
      "Epoch 168/1000\n",
      "3/3 [==============================] - 0s 5ms/step - loss: 317.8834 - mae: 13.9550 - mse: 317.8834\n",
      "Epoch 169/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 336.2724 - mae: 14.2099 - mse: 336.2724\n",
      "Epoch 170/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 320.0047 - mae: 14.0110 - mse: 320.0047\n",
      "Epoch 171/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 335.0825 - mae: 14.1961 - mse: 335.0825\n",
      "Epoch 172/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 331.4253 - mae: 14.2646 - mse: 331.4253\n",
      "Epoch 173/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 319.5540 - mae: 14.0594 - mse: 319.5540\n",
      "Epoch 174/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 330.7746 - mae: 14.3410 - mse: 330.7746\n",
      "Epoch 175/1000\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 337.7983 - mae: 14.0869 - mse: 337.7983\n",
      "Epoch 176/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 351.6084 - mae: 14.6390 - mse: 351.6084\n",
      "Epoch 177/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 330.2829 - mae: 14.2501 - mse: 330.2829\n",
      "Epoch 178/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 332.9028 - mae: 14.3653 - mse: 332.9028\n",
      "Epoch 179/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 334.2449 - mae: 14.4398 - mse: 334.2449\n",
      "Epoch 180/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 333.8979 - mae: 14.3553 - mse: 333.8979\n",
      "Epoch 181/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 323.5497 - mae: 14.0997 - mse: 323.5497\n",
      "Epoch 182/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 326.1163 - mae: 13.9528 - mse: 326.1163\n",
      "Epoch 183/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 332.7064 - mae: 14.2580 - mse: 332.7064\n",
      "Epoch 184/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 339.4847 - mae: 14.5359 - mse: 339.4847\n",
      "Epoch 185/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 328.3265 - mae: 14.2521 - mse: 328.3265\n",
      "Epoch 186/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 334.6451 - mae: 14.2425 - mse: 334.6451\n",
      "Epoch 187/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 321.7839 - mae: 14.2385 - mse: 321.7839\n",
      "Epoch 188/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 335.7123 - mae: 14.5601 - mse: 335.7123\n",
      "Epoch 189/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 309.4943 - mae: 13.8459 - mse: 309.4943\n",
      "Epoch 190/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 324.5305 - mae: 14.0134 - mse: 324.5305\n",
      "Epoch 191/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 347.5385 - mae: 14.5476 - mse: 347.5385\n",
      "Epoch 192/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 347.2057 - mae: 14.3529 - mse: 347.2057\n",
      "Epoch 193/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 325.4173 - mae: 14.0082 - mse: 325.4173\n",
      "Epoch 194/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 326.3972 - mae: 14.1640 - mse: 326.3972\n",
      "Epoch 195/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 352.7927 - mae: 14.6837 - mse: 352.7927\n",
      "Epoch 196/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 336.8586 - mae: 14.3278 - mse: 336.8586\n",
      "Epoch 197/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 332.8845 - mae: 14.4411 - mse: 332.8845\n",
      "Epoch 198/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 319.0648 - mae: 13.8682 - mse: 319.0648\n",
      "Epoch 199/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 336.0229 - mae: 14.2775 - mse: 336.0229\n",
      "Epoch 200/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 328.8327 - mae: 14.2912 - mse: 328.8327\n",
      "Epoch 201/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 334.6663 - mae: 14.4506 - mse: 334.6663\n",
      "Epoch 202/1000\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 325.6690 - mae: 14.1541 - mse: 325.6690\n",
      "Epoch 203/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 362.6471 - mae: 14.9373 - mse: 362.6471\n",
      "Epoch 204/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 352.3123 - mae: 14.7735 - mse: 352.3123\n",
      "Epoch 205/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 333.1356 - mae: 14.2310 - mse: 333.1356\n",
      "Epoch 206/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 341.8202 - mae: 14.5793 - mse: 341.8202\n",
      "Epoch 207/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 322.1081 - mae: 14.0020 - mse: 322.1081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 208/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 313.8046 - mae: 13.9088 - mse: 313.8046\n",
      "Epoch 209/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 321.5238 - mae: 13.8433 - mse: 321.5238\n",
      "Epoch 210/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 310.5616 - mae: 13.8130 - mse: 310.5616\n",
      "Epoch 211/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 310.5057 - mae: 13.7475 - mse: 310.5057\n",
      "Epoch 212/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 325.1925 - mae: 14.1563 - mse: 325.1925\n",
      "Epoch 213/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 315.9429 - mae: 13.9274 - mse: 315.9429\n",
      "Epoch 214/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 311.7935 - mae: 13.8241 - mse: 311.7935\n",
      "Epoch 215/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 321.7407 - mae: 14.0352 - mse: 321.7407\n",
      "Epoch 216/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 318.7322 - mae: 14.0425 - mse: 318.7322\n",
      "Epoch 217/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 348.3420 - mae: 14.5302 - mse: 348.3420\n",
      "Epoch 218/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 342.7519 - mae: 14.4006 - mse: 342.7519\n",
      "Epoch 219/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 312.2915 - mae: 13.8322 - mse: 312.2915\n",
      "Epoch 220/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 353.6143 - mae: 14.9037 - mse: 353.6143\n",
      "Epoch 221/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 318.8043 - mae: 14.0039 - mse: 318.8043\n",
      "Epoch 222/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 328.7371 - mae: 14.1927 - mse: 328.7371\n",
      "Epoch 223/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 320.3362 - mae: 14.0544 - mse: 320.3362\n",
      "Epoch 224/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 333.4182 - mae: 14.2491 - mse: 333.4182\n",
      "Epoch 225/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 353.0338 - mae: 14.6419 - mse: 353.0338\n",
      "Epoch 226/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 336.0061 - mae: 14.2582 - mse: 336.0061\n",
      "Epoch 227/1000\n",
      "3/3 [==============================] - 0s 8ms/step - loss: 333.0204 - mae: 14.4219 - mse: 333.0204\n",
      "Epoch 228/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 322.7415 - mae: 14.0631 - mse: 322.7415\n",
      "Epoch 229/1000\n",
      "3/3 [==============================] - 0s 6ms/step - loss: 334.8952 - mae: 14.3379 - mse: 334.8952\n",
      "Epoch 230/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 323.5892 - mae: 14.0593 - mse: 323.5892\n",
      "Epoch 231/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 331.3276 - mae: 14.2509 - mse: 331.3276\n",
      "Epoch 232/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 360.3290 - mae: 15.0133 - mse: 360.3290\n",
      "Epoch 233/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 317.6243 - mae: 13.9354 - mse: 317.6243\n",
      "Epoch 234/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 338.9595 - mae: 14.5926 - mse: 338.9595\n",
      "Epoch 235/1000\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 328.0469 - mae: 14.3216 - mse: 328.0469\n",
      "Epoch 236/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 329.3205 - mae: 14.1548 - mse: 329.3205\n",
      "Epoch 237/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 327.7255 - mae: 14.2320 - mse: 327.7255\n",
      "Epoch 238/1000\n",
      "3/3 [==============================] - 0s 10ms/step - loss: 328.2243 - mae: 14.2740 - mse: 328.2243\n",
      "Epoch 239/1000\n",
      "3/3 [==============================] - 0s 9ms/step - loss: 337.3554 - mae: 14.4507 - mse: 337.3554\n",
      "Epoch 240/1000\n",
      "3/3 [==============================] - 0s 7ms/step - loss: 321.6217 - mae: 13.8431 - mse: 321.6217\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 1000\n",
    "early_stop = tf.keras.callbacks.EarlyStopping(monitor='mse', patience=50)     \n",
    "history = model.fit(train_ds,   callbacks=[early_stop], epochs=EPOCHS,  verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'sex': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>, 'age': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'thalach': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n",
      "1/1 - 0s - loss: 338.2635 - mae: 14.7156 - mse: 338.2635\n",
      "MAE:14.715617179870605\n",
      "MSE:338.26348876953125\n"
     ]
    }
   ],
   "source": [
    "loss, mae, mse = model.evaluate(test_ds, verbose=2)\n",
    "print(\"MAE:{}\\nMSE:{}\".format(mae, mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labels = test_dataset[PREDICTOR_FIELD].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'dict'> input: {'sex': <tf.Tensor 'ExpandDims_1:0' shape=(None, 1) dtype=string>, 'age': <tf.Tensor 'ExpandDims:0' shape=(None, 1) dtype=float64>, 'thalach': <tf.Tensor 'ExpandDims_2:0' shape=(None, 1) dtype=float64>}\n",
      "Consider rewriting this model with the Functional API.\n"
     ]
    }
   ],
   "source": [
    "test_predictions = model.predict(test_ds).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pred_outputs = {\n",
    "    \"pred\": test_predictions,\n",
    "    \"actual_value\": test_labels,\n",
    "}\n",
    "model_output_df = pd.DataFrame(model_pred_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>actual_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>126.575775</td>\n",
       "      <td>134.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>127.757805</td>\n",
       "      <td>170.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>137.408356</td>\n",
       "      <td>125.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>126.575775</td>\n",
       "      <td>120.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>141.381210</td>\n",
       "      <td>130.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          pred  actual_value\n",
       "41  126.575775         134.0\n",
       "42  127.757805         170.0\n",
       "43  137.408356         125.0\n",
       "44  126.575775         120.0\n",
       "45  141.381210         130.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert Regression Output to binary classification output\n",
    "model_output_df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to binary prediction for Brier score - resting bps above 130 \n",
    "def convert_to_binary(df, pred_field, actual_field):\n",
    "    # score is the field name we will use for predictions and is what Aequitas uses\n",
    "    df['score'] = df[pred_field].apply(lambda x: 1 if x>=130 else 0 )\n",
    "    # label_value is the field name we will use for the truth value and is what Aequitas uses\n",
    "    df['label_value'] = df[actual_field].apply(lambda x: 1 if x>=130 else 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pred</th>\n",
       "      <th>actual_value</th>\n",
       "      <th>score</th>\n",
       "      <th>label_value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>134.110626</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>141.381210</td>\n",
       "      <td>115.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>140.520813</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>126.575775</td>\n",
       "      <td>160.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>140.520813</td>\n",
       "      <td>140.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         pred  actual_value  score  label_value\n",
       "0  134.110626          95.0      1            0\n",
       "1  141.381210         115.0      1            0\n",
       "2  140.520813         170.0      1            1\n",
       "3  126.575775         160.0      0            1\n",
       "4  140.520813         140.0      1            1"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_df = convert_to_binary(model_output_df, 'pred', 'actual_value')\n",
    "binary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = binary_df['label_value'].values \n",
    "y_pred = binary_df['score'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.41304347826086957"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.26      0.27        19\n",
      "           1       0.50      0.52      0.51        27\n",
      "\n",
      "    accuracy                           0.41        46\n",
      "   macro avg       0.39      0.39      0.39        46\n",
      "weighted avg       0.41      0.41      0.41        46\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3908382066276803"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L4 - 2: Demographic Bias Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "- Using the Compas dataset prepared by Aequitas, perform a Fairness Disparity Analysis on the under 25 Asian female reference group. See the documentation for reference -https://github.com/dssg/aequitas. In particular focus your analysis on fairness and disparity for FPR and where applicable try to leverage some of the visualizations Aequitas provides."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aequitas Compas Dataset\n",
    "- Using 2016 dataset from ProPublica for automated criminal risk assessment algorithms and adapted from Aequitas notebook - https://github.com/dssg/aequitas/blob/master/docs/source/examples/compas_demo.ipynb\n",
    "- Preprocessed using this script --https://github.com/dssg/aequitas/blob/master/examples/compas_data_for_aequitas.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Aequitas Bias() class is used to calculate disparities between groups based on the crosstab returned by the Group() class get_crosstabs() method we used for preprocessing the dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions from Aequitas on Calculating Disparities across Reference Groups\n",
    "(adapted from https://github.com/dssg/aequitas/blob/master/docs/source/examples/compas_demo.ipynb)\n",
    "\n",
    "Disparities are calculated as a ratio of a metric for a group of interest compared to a base group. For example, the False Negative Rate Disparity for black defendants vis-a-vis whites is:$$Disparity_{FNR} =  \\frac{FNR_{black}}{FNR_{white}}$$\n",
    "\n",
    "Below, we use get_disparity_predefined_groups() which allows us to choose reference groups that clarify the output for the practitioner.\n",
    "\n",
    "The Aequitas Bias() class includes two additional get disparity functions: get_disparity_major_group() and get_disparity_min_metric(), which automate base group selection based on sample majority (across each attribute) and minimum value for each calculated bias metric, respectively.\n",
    "\n",
    "The get_disparity_predefined_groups() allows user to define a base group for each attribute.\n",
    "\n",
    "Disparities Calculated Calcuated:\n",
    "- True Positive Rate Disparity\t'tpr_disprity'\n",
    "- True Negative Rate\t'tnr_disparity'\n",
    "- False Omission Rate\t'for_disparity'\n",
    "- False Discovery Rate\t'fdr_disparity'\n",
    "- False Positive Rate\t'fpr_disparity'\n",
    "- False NegativeRate\t'fnr_disparity'\n",
    "- Negative Predictive Value\t'npv_disparity'\n",
    "- Precision Disparity\t'precision_disparity'\n",
    "- Predicted Positive Ratio$_k$ Disparity\t'ppr_disparity'\n",
    "- Predicted Positive Ratio$_g$ Disparity\t'pprev_disparity'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How do I interpret calculated disparity ratios?**\n",
    "The calculated disparities from the dataframe returned by the Bias() class get_disparity_ methods are in relation to a reference group, which will always have a disparity of 1.0.\n",
    "\n",
    "The differences in False Positive Rates, noted in the discussion of the Group() class above, are clarified using the disparity ratio (fpr_disparity). Black people are falsely identified as being high or medium risks 1.9 times the rate for white people.\n",
    "\n",
    "As seen above, False Discovery Rates have much less disparity (fdr_disparity), or fraction of false postives over predicted positive in a group. As reference groups have disparity = 1 by design in Aequitas, the lower disparity is highlighted by the fdr_disparity value close to 1.0 (0.906) for the race attribute group 'African-American' when disparities are calculated using predefined base group 'Caucasian'. Note that COMPAS is calibrated to balance False Positive Rate and False Discovery Rates across groups.\n",
    "\n",
    "\n",
    "**How does the selected reference group affect disparity calculations?**\n",
    "Disparities calculated in the the Aequitas Bias() class based on the crosstab returned by the Group() class get_crosstabs() method can be derived using several different base gorups. In addition to using user-specified groups illustrated above, Aequitas can automate base group selection based on dataset characterisitcs:\n",
    "\n",
    "Evaluating disparities calculated in relation to a different 'race' reference group\n",
    "Changing even one attribute in the predefined groups will alter calculated disparities. When a different pre-defined group 'Hispanic' is used, we can see that Black people are 2.1 times more likely to be falsely identified as being high or medium risks as Hispanic people are (compared to 1.9 times more likely than white people), and even less likely to be falsely identified as low risk when compared to Hispanic people rather than white people."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './data/compas_for_aequitas.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-834216e6383d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Use Aequitas Data that was transformed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mcompas_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"./data/compas_for_aequitas.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    603\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    604\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 605\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    607\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    812\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1043\u001b[0m             )\n\u001b[1;32m   1044\u001b[0m         \u001b[0;31m# error: Too many arguments for \"ParserBase\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_failover_to_python\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1860\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1861\u001b[0m         \u001b[0;31m# open handles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1862\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open_handles\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1863\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1864\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"storage_options\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"encoding\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"memory_map\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_open_handles\u001b[0;34m(self, src, kwds)\u001b[0m\n\u001b[1;32m   1355\u001b[0m         \u001b[0mLet\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mreaders\u001b[0m \u001b[0mopen\u001b[0m \u001b[0mIOHanldes\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mthey\u001b[0m \u001b[0mare\u001b[0m \u001b[0mdone\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtheir\u001b[0m \u001b[0mpotential\u001b[0m \u001b[0mraises\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m         \"\"\"\n\u001b[0;32m-> 1357\u001b[0;31m         self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1358\u001b[0m             \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1359\u001b[0m             \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    637\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    638\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 639\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    640\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './data/compas_for_aequitas.csv'"
     ]
    }
   ],
   "source": [
    "# Use Aequitas Data that was transformed \n",
    "compas_df = pd.read_csv(\"./data/compas_for_aequitas.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compas_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-770b29c2aacf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcompas_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'compas_df' is not defined"
     ]
    }
   ],
   "source": [
    "compas_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aequitas\n",
    "from aequitas.preprocessing import preprocess_input_df\n",
    "from aequitas.group import Group\n",
    "from aequitas.plotting import Plot\n",
    "from aequitas.bias import Bias\n",
    "from aequitas.fairness import Fairness\n",
    "\n",
    "ae_subset_df = compas_df[['sex', 'age_cat', 'race', 'score', 'label_value']]\n",
    "ae_df, _ = preprocess_input_df(ae_subset_df)\n",
    "g = Group()\n",
    "xtab, _ = g.get_crosstabs(ae_df)\n",
    "absolute_metrics = g.list_absolute_metrics(xtab)\n",
    "clean_xtab = xtab.fillna(-1)\n",
    "aqp = Plot()\n",
    "b = Bias()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarized Metric View"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "absolute_metrics = g.list_absolute_metrics(xtab)\n",
    "xtab[[col for col in xtab.columns if col not in absolute_metrics]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtab[['attribute_name', 'attribute_value'] + absolute_metrics].round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = aqp.plot_group_metric_all(xtab, metrics=['tpr', 'fpr', 'ppr', 'pprev', 'fnr'], ncols=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add Reference Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bdf = b.get_disparity_predefined_groups(clean_xtab, \n",
    "                    original_df=ae_df, \n",
    "                    ref_groups_dict={'race':'Asian', 'sex':'Female', 'age_cat':'Less than 25'},\n",
    "                    alpha=0.05, \n",
    "                    check_significance=False)\n",
    "\n",
    "f = Fairness()\n",
    "fdf = f.get_group_value_fairness(bdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FPR Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " fpr_disparity = aqp.plot_disparity(bdf, group_metric='fpr_disparity', \n",
    "                                       attribute_name='race')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "African Americans are over 5x more likely to be falsely identified as well as Hispanic and Caucasian have over 2x more likely to be falsely identified than Asian."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Absolute Value Fairness Determination\n",
    "- Red = False/Not Fair\n",
    "- Green = True/Fair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr_fairness = aqp.plot_fairness_group(fdf, group_metric='fpr', title=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## L4 - 3: Uncertainty Estimation Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "- Given the Swiss heart disease dataset we have been working with, create an uncertainty estimation model that accounts for Epistemic Uncertainty as well. Provide the mean and standard deviation outputs.\n",
    "- https://blog.tensorflow.org/2019/03/regression-with-probabilistic-layers-in.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_probability as tfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Adapted from Tensorflow Probability Regression tutorial  https://github.com/tensorflow/probability/blob/master/tensorflow_probability/examples/jupyter_notebooks/Probabilistic_Layers_Regression.ipynb    \n",
    "'''\n",
    "def posterior_mean_field(kernel_size, bias_size=0, dtype=None):\n",
    "    n = kernel_size + bias_size\n",
    "    c = np.log(np.expm1(1.))\n",
    "    return tf.keras.Sequential([\n",
    "        tfp.layers.VariableLayer(2*n, dtype=dtype),\n",
    "        tfp.layers.DistributionLambda(lambda t: tfp.distributions.Independent(\n",
    "            tfp.distributions.Normal(loc=t[..., :n],\n",
    "                                     scale=1e-5 + tf.nn.softplus(c + t[..., n:])),\n",
    "            reinterpreted_batch_ndims=1)),\n",
    "    ])\n",
    "\n",
    "\n",
    "def prior_trainable(kernel_size, bias_size=0, dtype=None):\n",
    "    n = kernel_size + bias_size\n",
    "    return tf.keras.Sequential([\n",
    "        tfp.layers.VariableLayer(n, dtype=dtype),\n",
    "        tfp.layers.DistributionLambda(lambda t: tfp.distributions.Independent(\n",
    "            tfp.distributions.Normal(loc=t, scale=1),\n",
    "            reinterpreted_batch_ndims=1)),\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_seq_prob_model(feature_layer):\n",
    "    model = tf.keras.Sequential([\n",
    "        feature_layer,\n",
    "        tf.keras.layers.Dense(150, activation='relu'),\n",
    "        tf.keras.layers.Dense(75, activation='relu'),\n",
    "           tfp.layers.DenseVariational(1+1, posterior_mean_field, prior_trainable),        \n",
    "        tfp.layers.DistributionLambda(            \n",
    "            lambda t:tfp.distributions.Normal(loc=t[..., :1],\n",
    "                                            scale=1e-3 + tf.math.softplus(0.1 * t[...,1:])\n",
    "                                             )\n",
    "        ),\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "def build_prob_model(train_ds,   feature_layer,  epochs=5, loss_metric='mse'):\n",
    "    model = build_seq_prob_model(feature_layer)\n",
    "    negloglik = lambda y, rv_y: -rv_y.log_prob(y)\n",
    "    loss = negloglik\n",
    "    model.compile(optimizer='adam', loss=loss, metrics=[loss_metric])\n",
    "    history = model.fit(train_ds, \n",
    "                        epochs=epochs)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_model, history = build_prob_model(train_ds, dense_feature_layer,  epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_list = ['sex', 'age', 'thalach']\n",
    "x_tst = dict(test_dataset[feature_list])\n",
    "yhat = prob_model(x_tst)\n",
    "prob_preds = prob_model.predict(test_ds)\n",
    "m = yhat.mean()\n",
    "s = yhat.stddev()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_outputs = {\n",
    "    \"pred\": prob_preds.flatten(),\n",
    "     \"actual_value\": test_dataset['trestbps'].values,\n",
    "    \"pred_mean\": m.numpy().flatten(),\n",
    "    \"pred_std\": s.numpy().flatten()\n",
    "}\n",
    "prob_output_df = pd.DataFrame(prob_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_output_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhats = [prob_model(x_tst) for _ in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, yhat in enumerate(yhats):\n",
    "    m = np.squeeze(yhat.mean())\n",
    "    s = np.squeeze(yhat.stddev())\n",
    "    print(\"Mean distributions sampled:{}\".format(m))\n",
    "    print(\"Standard deviation distributions sampled:{}\".format(s))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
